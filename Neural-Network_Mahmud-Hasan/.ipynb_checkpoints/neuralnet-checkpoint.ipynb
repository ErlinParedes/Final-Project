{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e256ba-9632-485e-a343-e15231585b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural nets are essentially trying to fit a fnx onto \n",
    "\n",
    "# 28 x 28 pixel image\n",
    "# as the images are greyscale, each pixel has value 0 (black) to 255 (white)\n",
    "\n",
    "# represent this first as a matrix, each row being an example and having 784 columns\n",
    "# corresponding to each pixel in the image, brightness of pixels\n",
    "\n",
    "# transpose this matrix such that each column is an example and each column has 784 rows\n",
    "\n",
    "# input layer: 784 nodes for each pixel\n",
    "# hiden layer: 10 nodes\n",
    "# ouput laye: 10 nodes for each possible digit classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7abcf6-aeb8-446d-a44a-9aea97fa16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cca54f5-ab28-414a-86e8-3189dee18347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing training data as pandas dataframe\n",
    "curr_dir = os.getcwd()\n",
    "path = os.path.join(curr_dir, '../train.csv')\n",
    "\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f589b857-db51-44d9-8b12-643e34b50637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do the maths use numpy array\n",
    "data = np.array(data)\n",
    "m, n = data.shape # m is the rows, n is columns\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69162c3a-df9e-47d0-bc06-0af9d12db6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving some for test, 1000 \n",
    "data_dev = data[0:1000].T\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:n]\n",
    "X_dev = X_dev / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "401d68f0-ebfa-4a1a-a81e-e9f88dad3923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rest is training data\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255.\n",
    "_,m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5344cd6-2681-47b7-8725-ff24916bcdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data\n",
      "X_train:  (784, 41000)\n",
      "Y_train:  (41000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of data\")\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"Y_train: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7bdcb59-5153-43a9-9b9f-1081012f7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    w1 = np.random.randn(10, 784)  # random starting weights from -0.5 to 0.5 of size 10 by 784 since we are \n",
    "                                         # multiplying weight by  input which is a column of the data 784 x 1\n",
    "    b1 = np.random.randn(10, 1)     # random bais weight 10 x 1 because ouput of ^ mult 784x1 * 10x784 is 10x1\n",
    "    w2 = np.random.randn(10, 10) \n",
    "    b2 = np.random.randn(10, 1) \n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fea7c62a-49b2-4b46-9974-9889dfaacfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward propegation\n",
    "# running image through the network to see what network outputs\n",
    "# A0 = x the input   (input layer 784 x m) \n",
    "# Z1 = w1 * A0 + b1   (weight (10 x 784) dot input + bias (10 x 1)) => 10 x m output) (think of this as the synapes)\n",
    "# A1 = ReLU(Z1)   (apply activation function ReLU still 10x1 matrix)\n",
    "# Z2 = w2 * A1 + b2 (again this is like the connection between neuron/nodes)\n",
    "# A2 = softmax(Z2) (another activation function, softmax, which helps turn the outputs into a probability)\n",
    "\n",
    "# goes through each element in Z, returns relu of it\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def softmax(Z):\n",
    "    Z_shifted = Z - np.max(Z)\n",
    "    return np.exp(Z_shifted) / np.sum(np.exp(Z_shifted))  # makes it such that the values of Z will sum to 1, giving percentage\n",
    "\n",
    "def forward_prop(w1, b1, w2, b2, X):\n",
    "    Z1 = w1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = w2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c816bfb8-2890-4c5e-90df-d4aa26c286fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the correct weights and biases? that is determined in\n",
    "# backwards propegation\n",
    "# find out how much the prediction is off from the correct result, error, and determine how much the previous weight\n",
    "# and biases contriubte to this, and then adjust\n",
    "# dZ2 = A2 - Y    (take prediction and subtract the correct value, note that the node outputs a 10x1 matrix,\n",
    "#                  the correct matrix is similar execpt every row is 0 except the index for the correct number)\n",
    "# dw2 = 1/m * dZ2 * A1^T   (derivative of loss fnx with respect to the weights)\n",
    "# db2 = 1/m * SUM(dZ2)   (average of the errors)\n",
    "# dZ1 = w2^T * dZ2 * f'()   (this is sortve like propegation in reverse)\n",
    "# dw1 = 1/m * dZ! * A0^T   (derivative of loss fnx with respect to the weights)\n",
    "# db1 = 1/m * SUM(dZ1)\n",
    "\n",
    "def one_hot(Y):\n",
    "    # create the label matrix for each data and set the correct identifier as 1\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T # remember to flip because we want columns to be data\n",
    "    return one_hot_Y\n",
    "\n",
    "def dydxReLU(Z):\n",
    "    return Z > 0 # if x less than 0 returns 0 if greater return 1, slope of y=z\n",
    "\n",
    "def back_prop(Z1, A1, Z2, A2, w1, w2, X, Y): # to compare with actual \n",
    "    one_hot_Y = one_hot(Y)\n",
    "    m = one_hot_Y.size\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dw2 = 1/m * dZ2.dot(A1.T)\n",
    "    db2 = 1/m * np.sum(dZ2)\n",
    "    dZ1 = w2.T.dot(dZ2) * dydxReLU(Z1)\n",
    "    dw1 = 1/m * dZ1.dot(X.T)\n",
    "    db1 = 1/m * np.sum(dZ1)\n",
    "    return dw1, db1, dw2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7db2317a-8a16-45d3-af99-dfba3b579a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update parameters usinig learning rate r (hyper parameter)\n",
    "# w1 = w1 - r * dw1\n",
    "# b1 = b1 - r * db1\n",
    "# w2 = w2 - r * dw2\n",
    "# b2 = b2 - r * db2\n",
    "\n",
    "def update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, rate):\n",
    "    w1 = w1 - rate * dw1\n",
    "    b1 = b1 - rate * db1\n",
    "    w2 = w2 - rate * dw2\n",
    "    b2 = b2 - rate * db2\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2718208-bf49-4d33-a3cc-66e101b93013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine accuracy of model\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    return np.sum(predictions == Y) / Y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c11c324-417d-4bd2-b405-d24704515e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe gradient descent\n",
    "# iterations how many times updating params\n",
    "\n",
    "def gradient_descent(X, Y, iterations, rate):\n",
    "    w1, b1, w2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(w1, b1, w2, b2, X)\n",
    "        dw1, db1, dw2, db2 = back_prop(Z1, A1, Z2, A2, w1, w2, X, Y)\n",
    "        w1, b1, w2, b2 = update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, rate)\n",
    "        if i % 50 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            print(\"Accuracy: \", get_accuracy(get_predictions(A2), Y))\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af1ddb2b-42d6-471c-a70f-53385f1f5fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Accuracy:  0.15490243902439024\n",
      "Iteration:  50\n",
      "Accuracy:  0.19975609756097562\n",
      "Iteration:  100\n",
      "Accuracy:  0.13046341463414635\n",
      "Iteration:  150\n",
      "Accuracy:  0.09853658536585366\n",
      "Iteration:  200\n",
      "Accuracy:  0.09853658536585366\n",
      "Iteration:  250\n",
      "Accuracy:  0.09853658536585366\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = gradient_descent(X_train, Y_train, 300, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d36c97-9d24-4d6c-86c8-d36be8db3421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
