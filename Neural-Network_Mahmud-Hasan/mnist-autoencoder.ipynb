{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7abcf6-aeb8-446d-a44a-9aea97fa16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cca54f5-ab28-414a-86e8-3189dee18347",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "path = os.path.join(curr_dir, '../train.csv')\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "data = np.array(data)\n",
    "m, n = data.shape # m is the rows, n is columns\n",
    "np.random.shuffle(data)\n",
    "\n",
    "X_train = torch.from_numpy(data[:, 1:] / 255.).float()\n",
    "Y_train = torch.from_numpy(data[:, 0]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "401d68f0-ebfa-4a1a-a81e-e9f88dad3923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder settings\n",
    "n_inputs = 784\n",
    "n_hidden = 64  # codings\n",
    "n_outputs = n_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48442a52-db1d-40dd-9a29-8eeabadb7447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    w1 = torch.randn(n_inputs, n_hidden)\n",
    "    b1 = torch.zeros(n_hidden)\n",
    "    w2 = torch.randn(n_hidden, n_outputs)\n",
    "    b2 = torch.zeros(n_outputs)\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5344cd6-2681-47b7-8725-ff24916bcdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, w1, b1, w2, b2):\n",
    "    Z1 = X @ w1 + b1\n",
    "    A1 = torch.sigmoid(Z1)  # codings\n",
    "    Z2 = A1 @ w2 + b2\n",
    "    A2 = torch.sigmoid(Z2)  # reconstructed inputs\n",
    "    return Z1, A1, Z2, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d36c97-9d24-4d6c-86c8-d36be8db3421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(X, Z1, A1, Z2, A2, w1, w2):\n",
    "    dZ2 = (A2 - X) * A2 * (1 - A2)\n",
    "    dw2 = A1.t() @ dZ2\n",
    "    db2 = torch.sum(dZ2, axis=0)\n",
    "    dZ1 = dZ2 @ w2.t() * A1 * (1 - A1)\n",
    "    dw1 = X.t() @ dZ1\n",
    "    db1 = torch.sum(dZ1, axis=0)\n",
    "    return dw1, db1, dw2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dde23f7-3c5f-4eb1-b127-7ac8ef23fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha):\n",
    "    w1 = w1 - alpha * dw1\n",
    "    b1 = b1 - alpha * db1\n",
    "    w2 = w2 - alpha * dw2\n",
    "    b2 = b2 - alpha * db2\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8970e779-903e-4c1b-9cf0-4ac349e755b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(X, alpha, iterations):\n",
    "    w1, b1, w2, b2 = init_params()\n",
    "    for iteration in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(X, w1, b1, w2, b2)\n",
    "        dw1, db1, dw2, db2 = backward_prop(X, Z1, A1, Z2, A2, w1, w2)\n",
    "        w1, b1, w2, b2 = update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha)\n",
    "        if iteration % 50 == 0:\n",
    "            print(f\"Iteration: {iteration}\")\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f9401c-3f25-4722-8b06-b27561846b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 50\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = train_autoencoder(X_train, 0.01, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a93bf-fac9-416e-9f69-1238f6e5c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(w1, b1, w2, b2, n):\n",
    "    # Generate n random codings\n",
    "    codings = torch.randn(n, n_hidden)\n",
    "    \n",
    "    # Pass the codings through the decoder\n",
    "    Z2 = codings @ w2 + b2\n",
    "    images = torch.sigmoid(Z2)\n",
    "    \n",
    "    # Plot the images\n",
    "    fig, axes = plt.subplots(1, n, figsize=(n, 1))\n",
    "    for image, ax in zip(images, axes):\n",
    "        ax.imshow(image.detach().numpy().reshape(28, 28), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba4ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(w1, b1, w2, b2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebfe3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
